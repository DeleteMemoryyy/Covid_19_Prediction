{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "additional_path = '/tf/Lecture/Covid_19_Prediction_Stacking/data/owid-covid-data.csv'\n",
    "D_path = '/tf/Lecture/Covid_19_Prediction_Stacking/data/time_series_covid19_confirmed_global.csv'\n",
    "A_path = '/tf/Lecture/Covid_19_Prediction_Stacking/data/time_series_covid19_deaths_global.csv'\n",
    "R_path = '/tf/Lecture/Covid_19_Prediction_Stacking/data/time_series_covid19_recovered_global.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "hard_hit_country = ['US', 'India', 'Brazil', 'Russia', 'France', 'Italy']\n",
    "relapse_country = ['Italy', 'Germany', 'Denmark', 'Switzerland', 'Russia', 'Austria']\n",
    "lack_data_countries = ['Brazil', 'Germany']\n",
    "# interested_countries = list((set(hard_hit_country) | set(relapse_country)) - set(lack_data_countries))\n",
    "interested_countries = list(set(relapse_country) - set(lack_data_countries))\n",
    "all_column_name = 'iso_code,continent,location,date,total_cases,new_cases,new_cases_smoothed,total_deaths,new_deaths,new_deaths_smoothed,total_cases_per_million,new_cases_per_million,new_cases_smoothed_per_million,total_deaths_per_million,new_deaths_per_million,new_deaths_smoothed_per_million,icu_patients,icu_patients_per_million,hosp_patients,hosp_patients_per_million,weekly_icu_admissions,weekly_icu_admissions_per_million,weekly_hosp_admissions,weekly_hosp_admissions_per_million,total_tests,new_tests,total_tests_per_thousand,new_tests_per_thousand,new_tests_smoothed,new_tests_smoothed_per_thousand,tests_per_case,positive_rate,tests_units,stringency_index,population,population_density,median_age,aged_65_older,aged_70_older,gdp_per_capita,extreme_poverty,cardiovasc_death_rate,diabetes_prevalence,female_smokers,male_smokers,handwashing_facilities,hospital_beds_per_thousand,life_expectancy,human_development_index'\n",
    "\n",
    "column_names = ['iso_code',\n",
    "                'continent',\n",
    "                'location',\n",
    "                'date',\n",
    "                'total_cases',\n",
    "                'new_cases',\n",
    "                'new_cases_smoothed',\n",
    "                'total_deaths',\n",
    "                'new_deaths',\n",
    "                'new_deaths_smoothed',\n",
    "                'total_cases_per_million',\n",
    "                'new_cases_per_million',\n",
    "                'new_cases_smoothed_per_million',\n",
    "                'total_deaths_per_million',\n",
    "                'new_deaths_per_million',\n",
    "                'new_deaths_smoothed_per_million',\n",
    "                'icu_patients',\n",
    "                'icu_patients_per_million',\n",
    "                'hosp_patients',\n",
    "                'hosp_patients_per_million',\n",
    "                'weekly_icu_admissions',\n",
    "                'weekly_icu_admissions_per_million',\n",
    "                'weekly_hosp_admissions',\n",
    "                'weekly_hosp_admissions_per_million',\n",
    "                'total_tests',\n",
    "                'new_tests',\n",
    "                'total_tests_per_thousand',\n",
    "                'new_tests_per_thousand',\n",
    "                'new_tests_smoothed',\n",
    "                'new_tests_smoothed_per_thousand',\n",
    "                'tests_per_case',\n",
    "                'positive_rate',\n",
    "\n",
    "                'tests_units',\n",
    "                'stringency_index',\n",
    "                'population',\n",
    "                'population_density',\n",
    "                'median_age',\n",
    "                'aged_65_older',\n",
    "                'aged_70_older',\n",
    "                'gdp_per_capita',\n",
    "                'extreme_poverty',\n",
    "                'cardiovasc_death_rate',\n",
    "                'diabetes_prevalence',\n",
    "                'female_smokers',\n",
    "                'male_smokers',\n",
    "                'handwashing_facilities',\n",
    "                'hospital_beds_per_thousand',\n",
    "                'life_expectancy',\n",
    "                'human_development_index']\n",
    "\n",
    "column_names = all_column_name.split(',')\n",
    "\n",
    "\n",
    "good_features = [\n",
    "                 # 'stringency_index',\n",
    "                 'population',\n",
    "                 'population_density',\n",
    "                 'median_age',\n",
    "                 'aged_65_older',\n",
    "                 'aged_70_older',\n",
    "                 'gdp_per_capita',\n",
    "                 # 'extreme_poverty',\n",
    "                 'cardiovasc_death_rate',\n",
    "                 'diabetes_prevalence',\n",
    "                 'male_smokers',\n",
    "                 'female_smokers',\n",
    "                 'hospital_beds_per_thousand',\n",
    "                 'life_expectancy',\n",
    "                 'human_development_index']\n",
    "good_time_sequences_features = ['new_tests',                                             'new_tests_per_thousand',\n",
    "    'total_tests', 'total_tests_per_thousand','positive_rate']\n",
    "good_generated_features=[\n",
    "                                         'total_cases_per_million',\n",
    "                                         'new_cases_per_million',\n",
    "                                         'new_cases_smoothed_per_million',\n",
    "                                         'total_deaths_per_million',\n",
    "                                         'new_deaths_per_million',\n",
    "                                         'new_deaths_smoothed_per_million',\n",
    "                                         'total_tests',\n",
    "                                         'new_tests',\n",
    "                                         'total_tests_per_thousand',\n",
    "                                         'new_tests_per_thousand',\n",
    "                                         'new_tests_smoothed',\n",
    "                                         'new_tests_smoothed_per_thousand',\n",
    "                                         'tests_per_case']\n",
    "\n",
    "input_features=[\n",
    "    'date',\n",
    "    # 'start_days',\n",
    "    # 'date_days'\n",
    "                                             'total_cases',\n",
    "    # 'total_cases_smoothed',\n",
    "    # 'total_cases_per_million',\n",
    "\n",
    "                                             'new_cases',\n",
    "                                             # 'new_cases_smoothed',\n",
    "                                             # 'new_cases_per_million',\n",
    "                                             # 'new_cases_smoothed_per_million',\n",
    "                                             'total_deaths',\n",
    "                                             'new_deaths',\n",
    "                                             # 'new_deaths_smoothed',\n",
    "                                             # 'new_deaths_per_million',\n",
    "                                             # 'new_deaths_smoothed_per_million',\n",
    "    'total_recovered',\n",
    "                                             'new_recovered',\n",
    "                                             # 'new_recovered_per_million',\n",
    "                                             'total_tests',\n",
    "                                             'new_tests',\n",
    "                                             # 'new_tests_per_thousand',\n",
    "                                             # 'total_tests_per_thousand',\n",
    "    'death_rate',\n",
    "    'recovery_rate',\n",
    "    'positive_rate']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "addition_data = pd.read_csv(additional_path)\n",
    "addition_data['location'].replace('United States', 'US', inplace=True)\n",
    "addition_data = addition_data[addition_data['location'].isin(interested_countries)].reset_index(drop=True)\n",
    "addition_data['datetime'] = 1\n",
    "def generate_date_time(row):\n",
    "    date_str = row['date'].split('-')\n",
    "    year = int(date_str[0])\n",
    "    month = int(date_str[1])\n",
    "    day = int(date_str[2])\n",
    "    date_time = int(datetime.date(year, month, day).strftime('%j'))\n",
    "    if year > 2020:\n",
    "        date_time += 366\n",
    "    row['datetime'] = date_time\n",
    "    row['date'] = '{}/{}/{}'.format(month, day, year - 2000)\n",
    "    return row\n",
    "addition_data = addition_data.apply(generate_date_time, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "addition_seq_df = addition_data[['location', 'date'] + good_time_sequences_features]\n",
    "addition_seq_df = addition_seq_df[addition_data['total_cases']>0].reset_index(drop=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "==new_tests==\n",
      "Switzerland\n",
      "Italy\n",
      "Russia\n",
      "Denmark\n",
      "Austria\n"
     ]
    }
   ],
   "source": [
    "# for feature in good_time_sequences_features:\n",
    "feature = 'new_tests'\n",
    "print('----------------')\n",
    "print('==' + feature + '==')\n",
    "for country in interested_countries:\n",
    "    print(country)\n",
    "    t_data = addition_seq_df[addition_seq_df['location']==country][feature]\n",
    "    # print(t_data.isnull().value_counts())\n",
    "    # print(t_data.value_counts())\n",
    "    t_filled_data = t_data.fillna(method='ffill').fillna(t_data.min())\n",
    "    # print(t_filled_data.value_counts())\n",
    "    # for i, v in enumerate(t_filled_data):\n",
    "    #     print(i, v)\n",
    "\n",
    "    for i in t_filled_data.index.values:\n",
    "        addition_seq_df.at[i,feature] = t_filled_data[i]\n",
    "\n",
    "    # t_data = addition_seq_df[addition_seq_df['location']==country][feature]\n",
    "    # print(t_data.isnull().value_counts())\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# feature = 'tests_per_case'\n",
    "# feature_df = interested_data[['location', 'date', feature]]\n",
    "# feature_df = feature_df.reset_index()\n",
    "# feature_with_data = feature_df[feature_df[feature].isnull()==False]\n",
    "# feature_with_data['location'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "D_data = pd.read_csv(D_path)\n",
    "D_interested = D_data[(D_data['Country/Region'].isin(interested_countries)) & (D_data['Province/State'].isnull())]\n",
    "D_interested = D_interested.reset_index(drop=True).drop(columns=['Province/State', 'Lat', 'Long'])\n",
    "D_interested = D_interested.rename(columns={'Country/Region':'location'})\n",
    "D_interested = D_interested.set_index('location')\n",
    "D_interested = D_interested.transpose()\n",
    "\n",
    "A_data = pd.read_csv(A_path)\n",
    "A_interested = A_data[(A_data['Country/Region'].isin(interested_countries)) & (A_data['Province/State'].isnull())]\n",
    "A_interested = A_interested.reset_index(drop=True).drop(columns=['Province/State', 'Lat', 'Long'])\n",
    "A_interested = A_interested.rename(columns={'Country/Region':'location'})\n",
    "A_interested = A_interested.set_index('location')\n",
    "A_interested = A_interested.transpose()\n",
    "\n",
    "R_data = pd.read_csv(R_path)\n",
    "R_interested = R_data[(R_data['Country/Region'].isin(interested_countries)) & (R_data['Province/State'].isnull())]\n",
    "R_interested = R_interested.reset_index(drop=True).drop(columns=['Province/State', 'Lat', 'Long'])\n",
    "R_interested = R_interested.rename(columns={'Country/Region':'location'})\n",
    "R_interested = R_interested.set_index('location')\n",
    "R_interested = R_interested.transpose()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "location\nAustria        2/25/20\nDenmark        2/27/20\nItaly          1/31/20\nRussia         1/31/20\nSwitzerland    2/25/20\nName: first_discovery_date, dtype: object"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demography_data = addition_data[['location'] + good_features].drop_duplicates().reset_index(drop=True).set_index('location')\n",
    "demography_data['first_discovery_date'] = '1/22/20'\n",
    "# country = 'France'\n",
    "# D_interested[country][D_interested[country] > 0.0].index[0]\n",
    "for country in interested_countries:\n",
    "    first_D_data = D_interested[country][D_interested[country] > 0.0].index[0]\n",
    "    demography_data.at[country, 'first_discovery_date'] = first_D_data\n",
    "demography_data['first_discovery_date']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "countries_data = {}\n",
    "for country in interested_countries:\n",
    "    discovery_data = demography_data['first_discovery_date'][country]\n",
    "    days = len(D_interested[country][discovery_data:])\n",
    "    df = pd.DataFrame(np.zeros(shape=(days, len(input_features))), columns=input_features)\n",
    "    \n",
    "    df['date'] = D_interested[country][discovery_data:].index.values\n",
    "    df['total_cases'] = D_interested[country][discovery_data:].values\n",
    "    df['total_deaths'] = A_interested[country][discovery_data:].values\n",
    "    df['total_recovered'] = R_interested[country][discovery_data:].values\n",
    "    t_addition = addition_seq_df[addition_seq_df['location']==country]\n",
    "    for i in range(days):\n",
    "        df.at[i, 'new_tests'] = t_addition[t_addition['date'] == df['date'][i]]['new_tests']\n",
    "\n",
    "    df.at[0, 'new_cases'] = df['total_cases'][0]\n",
    "    df.at[0, 'new_deaths'] = df['total_deaths'][0]\n",
    "    df.at[0, 'new_recovered'] = df['total_recovered'][0]\n",
    "    df.at[0, 'total_tests'] = df['new_tests'][0]\n",
    "    \n",
    "    for i in range(1, days):\n",
    "        df.at[i, 'new_cases'] = df['total_cases'][i] - df['total_cases'][i - 1]\n",
    "        df.at[i, 'new_deaths'] = df['total_deaths'][i] - df['total_deaths'][i - 1]\n",
    "        df.at[i, 'new_recovered'] = df['total_recovered'][i] - df['total_recovered'][i - 1]\n",
    "        df.at[i, 'total_tests'] = df['total_tests'][i - 1] + df['new_tests'][i]\n",
    "\n",
    "    df['death_rate'] = df['new_deaths'] / df['total_cases']\n",
    "    df['recovery_rate'] = df['new_recovered'] / df['total_cases']\n",
    "    df['positive_rate'] = df['new_cases'] / df['new_tests']\n",
    "\n",
    "    countries_data[country] = df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "base",
   "language": "python",
   "display_name": "conda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}